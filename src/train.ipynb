{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e0c6f7-88d5-4ec6-bad4-ad07d8096f83",
   "metadata": {},
   "source": [
    "## Novel Molecule Generation using Bidirectional-Recurrent Neural Networks with Attention Applied to Simplified Molecular Input Line Entry Sysem (SMILES)\n",
    "\n",
    "## Train\n",
    "\n",
    "author: anthony j. vasquez\n",
    "email: vanthony715@gmail.com / avasque1@jh.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ff2a3ee-51ca-4db7-a090-e35321048987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System:  Linux\n",
      "Machine Type::  x86_64\n",
      "Processor Count:  24 \n",
      "\n",
      "CUDA Version\n",
      "CUDNN Version: 90100\n",
      "Number of CUDA Devices: 2\n",
      "Active CUDA Device: 0\n",
      "Available devices: 2, Name: NVIDIA RTX A4000\n",
      "Current CUDA device: 0\n",
      "\n",
      "\n",
      "Using Device: \n",
      " cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "t0 = time.time()\n",
    "\n",
    "import sys\n",
    "sys.path.append('./data/')\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "##had a hard time with this setting on windows os using spyder and jypyter\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import platform\n",
    "print(\"Operating System: \", platform.system())\n",
    "print(\"Machine Type:: \", platform.machine())\n",
    "\n",
    "import multiprocessing as mp\n",
    "max_processors = mp.cpu_count()\n",
    "print('Processor Count: ', max_processors, '\\n')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import BRICS\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Descriptors import CalcMolDescriptors\n",
    "from rdkit.Chem.rdMolDescriptors import GetHashedMorganFingerprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from net import *\n",
    "from utils import *\n",
    "from custom_dataset import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache() #empty cache\n",
    "    print('CUDA Version')\n",
    "    print(f'CUDNN Version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Number of CUDA Devices: {torch.cuda.device_count()}')\n",
    "    print(f'Active CUDA Device: {torch.cuda.current_device()}')\n",
    "    print(f'Available devices: {torch.cuda.device_count()}, Name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Current CUDA device: {torch.cuda.current_device()}')\n",
    "    print('\\n')\n",
    "\n",
    "##hardware params\n",
    "# DEVICE = torch.device('cpu') #DEBUG\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using Device: \\n', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e871a2-9bc2-4747-92a7-23b6bf9956bd",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ddb5d5-a423-434c-a5e3-dc5160bd1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "##OS\n",
    "LINUX = True\n",
    "MULTI_GPU = True #trains using multiple gpus\n",
    "N_PROCESSORS = max_processors - 2\n",
    "\n",
    "##data\n",
    "HOLDOUT_PERC = 0.75\n",
    "TRAIN_BS = 128 #train batch size\n",
    "PREFETCH_FACTOR = 4 #effectively reduces gpu load time \n",
    "NUM_WORKERS = 8\n",
    "\n",
    "'''\n",
    "Current Best Config:\n",
    "Best trial config: {'lr_g': 0.0001413635808908355, 'lr_d': 0.016875269365452798, 'batch_size': 128, 'hidden_dim': 16, \n",
    "                    'optimizer': 'rmsprop', 'n_disc_steps': 1, 'clip_value': 0.006409295150167364}\n",
    "                    \n",
    "Best trial final loss: 0.6899543404579163\n",
    "'''\n",
    "\n",
    "##training\n",
    "N_EPOCHS = 50 #num of training epochs\n",
    "OPTIMIZER = 'rmsprop' ##or adam\n",
    "LRG = 0.004086800025392213 #learning rate generator\n",
    "LRD = 0.013448070902660135 #learning rate discriminator\n",
    "LRS_SZ = 5 #learning rate scheduler step size\n",
    "LRS_GAMMA = 0.99 #learning rate scheduler gamma\n",
    "BETAS = (0.5, 0.999) #momentum moving average\n",
    "DROPOUT_PROB = 0.5 #dropout\n",
    "WEIGHT_DECAY = 1e-5 #L2 Regularization\n",
    "RUN_EXTRA_TIMES = 3 #iterate over validator extra times for every one time that the generator ates\n",
    "EMBEDDING_DIM = 32 #how large of a vector to represent input data\n",
    "HIDDEN_DIM = 128 #learned embeddings\n",
    "N_LAYERS = 2 #num gru layers\n",
    "BIDIRECTIONAL = True #makes gru layer bidirectional\n",
    "N_HEADS = 4 #number of heads for attention, scaled dot-product for head's respective section of sequence\n",
    "CLIP_VALUE = 0.008101987508250374 ##WGAN discriminator clip value for training stabalization\n",
    "\n",
    "##inference\n",
    "N_SAMPLES = 1000\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "##visualization params\n",
    "SIGMA = 2 #loss smoothing for lineplot\n",
    "PRINT_LOSS_EVERY = 2 #how many epochs to output loss\n",
    "\n",
    "##logging\n",
    "RESULTS_PATH = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2587588-c844-4fb7-898d-bfc539c24e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Folder at:  ../results/epoch_50_exper_at_datetime_22-08-2024_09-56-44\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "def make_dir(path: str) -> None:\n",
    "    '''\n",
    "    Create results directory\n",
    "    '''\n",
    "    import shutil\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    print('Created Folder at: ', path)\n",
    "\n",
    "WRITEPATH = RESULTS_PATH + 'epoch_'+ str(N_EPOCHS) + '_exper_at_datetime_' + dt_string\n",
    "make_dir(WRITEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e7019-b80f-4509-9110-b89fcdcf89e6",
   "metadata": {},
   "source": [
    "#### Open SMILES Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbb68ac-ff6c-4c9f-9384-ebf253063245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len all smiles:  249456\n",
      "Len train smiles:  62364\n",
      "Len holdout smiles:  187092\n",
      "\n",
      "\n",
      "CPU times: user 237 ms, sys: 0 ns, total: 237 ms\n",
      "Wall time: 237 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Import the data\n",
    "data_file = pd.read_csv('../data/Zinc_all_smiles_data.txt', header = None)\n",
    "data_file.columns = ['smiles']\n",
    "smilesList = data_file['smiles'].tolist()\n",
    "\n",
    "##split dset\n",
    "train_smiles, holdout_smiles, _, _ = train_test_split(smilesList, smilesList, test_size=HOLDOUT_PERC, random_state=42)\n",
    "print('Len all smiles: ', len(smilesList))\n",
    "print('Len train smiles: ', len(train_smiles))\n",
    "print('Len holdout smiles: ', len(holdout_smiles))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6532e3e2-4fb4-4700-a264-c5397888934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 614 ms, sys: 9.81 ms, total: 624 ms\n",
      "Wall time: 624 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Example usage:\n",
    "vocab = build_vocabulary(smilesList)\n",
    "max_length = max(len(tokenize_smiles(smiles)) for smiles in smilesList)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3d097b-0953-437a-9d79-d61c509e76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Summary: \n",
      "smilesList Len:  249456\n",
      "vocab len:  254593\n",
      "max_length:  27\n",
      "\n",
      "\n",
      "CPU times: user 238 µs, sys: 0 ns, total: 238 µs\n",
      "Wall time: 237 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##define dataset\n",
    "dataset = SMILESDataset(train_smiles, vocab, max_length)\n",
    "\n",
    "##runs slightly faster using linux, because able to use num_workers > 0\n",
    "if LINUX:\n",
    "    dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True, pin_memory=True, prefetch_factor=PREFETCH_FACTOR, num_workers=NUM_WORKERS)\n",
    "else:\n",
    "    ##windows\n",
    "    dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True, pin_memory=True)\n",
    "\n",
    "print('Data Summary: ')\n",
    "print('smilesList Len: ', len(smilesList))\n",
    "print('vocab len: ', len(vocab))\n",
    "print('max_length: ', max_length)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08569a-29af-4a27-81cc-a1d68884606e",
   "metadata": {},
   "source": [
    "### Instantiate GAN and Discriminator Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d84ab8-00f1-4a8b-b0f1-99244d5715e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 1.52 s, sys: 370 ms, total: 1.89 s\n",
      "Wall time: 2.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##init networks\n",
    "n_gen = Generator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                  num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL).to(DEVICE)\n",
    "\n",
    "n_disc = Discriminator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                       num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL).to(DEVICE)\n",
    "\n",
    "if MULTI_GPU:\n",
    "    ##for multi-gpu\n",
    "    n_gen = nn.DataParallel(n_gen)\n",
    "    n_disc = nn.DataParallel(n_disc)\n",
    "\n",
    "##set optimization\n",
    "if OPTIMIZER == 'rmsprop':\n",
    "    g_opt = torch.optim.RMSprop(n_gen.parameters(), lr=LRG, weight_decay=WEIGHT_DECAY)\n",
    "    d_opt = torch.optim.RMSprop(n_disc.parameters(), lr=LRD, weight_decay=WEIGHT_DECAY)\n",
    "else: \n",
    "    g_opt = optim.Adam(n_gen.parameters(), lr=LRG, betas=BETAS, weight_decay=WEIGHT_DECAY)\n",
    "    d_opt = optim.Adam(n_disc.parameters(), lr=LRD, betas=BETAS, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "##set schedulers\n",
    "schedule_g = StepLR(g_opt, step_size=LRS_SZ, gamma=LRS_GAMMA)\n",
    "schedule_d = StepLR(d_opt, step_size=LRS_SZ, gamma=LRS_GAMMA)\n",
    "\n",
    "##init criterion\n",
    "crit = nn.BCELoss()\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ad908-5714-49da-8573-9e24c6787a12",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02dd763-5710-49d0-838f-f0b2da6afaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total generator param cnt:  74261698\n",
      "Trainable generator param cnt:  74261698\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal generator param cnt: ', count_parameters(n_gen))\n",
    "print('Trainable generator param cnt: ', count_trainable_parameters(n_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc3af1e-44ae-4bf8-99df-11ecc4491b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator(\n",
       "    (embedding): Embedding(254594, 32)\n",
       "    (gru): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=254594, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede9e83-6d7a-4bae-9e83-c7fa994ea081",
   "metadata": {},
   "source": [
    "### Descriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4bfd49-acc5-40a6-8336-3f52f261f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total discriminator param cnt:  8666945\n",
      "Trainable discriminator param cnt:  8666945\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal discriminator param cnt: ', count_parameters(n_disc))\n",
    "print('Trainable discriminator param cnt: ', count_trainable_parameters(n_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4d5263-2d8c-4459-aa38-056500080368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Discriminator(\n",
       "    (embedding): Embedding(254594, 32)\n",
       "    (gru): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (fc_reduce): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e36c28-ff8b-433a-9217-ddb8844f3555",
   "metadata": {},
   "source": [
    "### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3e547-77f1-4756-9d42-10783e86cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:54<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/50], D Loss: 1.35907, G Loss: 0.65724, Runtime/Epoch: 174.40892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:52<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:52<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], D Loss: 1.36378, G Loss: 0.75004, Runtime/Epoch: 172.67851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:52<00:00,  2.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:51<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], D Loss: 1.35964, G Loss: 0.64615, Runtime/Epoch: 171.46983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:53<00:00,  2.81it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:51<00:00,  2.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], D Loss: 1.37075, G Loss: 0.63682, Runtime/Epoch: 171.96816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:52<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:53<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], D Loss: 1.36889, G Loss: 0.67960, Runtime/Epoch: 173.93098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:51<00:00,  2.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:50<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/50], D Loss: 1.37223, G Loss: 0.68377, Runtime/Epoch: 170.47686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:50<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:51<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], D Loss: 1.36416, G Loss: 0.84112, Runtime/Epoch: 171.27170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:52<00:00,  2.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:51<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], D Loss: 1.37400, G Loss: 0.74942, Runtime/Epoch: 171.28895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:50<00:00,  2.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:50<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/50], D Loss: 1.35901, G Loss: 0.59078, Runtime/Epoch: 170.42282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 488/488 [02:50<00:00,  2.86it/s]\n",
      " 49%|███████████████████████████████████████▌                                         | 238/488 [01:24<01:27,  2.85it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist, gnet, dnet =  train_gan(generator=n_gen, discriminator=n_disc, g_optimizer=g_opt, d_optimizer=d_opt, criterion=crit, \n",
    "                              g_schedule=schedule_g, d_schedule=schedule_d, data_loader=dataloader, run_extra_times=RUN_EXTRA_TIMES, \n",
    "                              clip_value=CLIP_VALUE, n_epochs=N_EPOCHS, multi_gpu=MULTI_GPU, device=DEVICE, print_loss_every=PRINT_LOSS_EVERY)\n",
    "\n",
    "##save both networks\n",
    "torch.save(gnet.state_dict(), WRITEPATH + '/gnet.pt')\n",
    "torch.save(dnet.state_dict(), WRITEPATH + '/dnet.pt')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853dc92-f28d-4c5c-ae09-9be6616b069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plot_losses(history=hist, sigma=SIGMA, save=True, savepath=WRITEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd636bc-0ec3-432e-b6b1-c5a6598cd833",
   "metadata": {},
   "source": [
    "### Generate Molecules Using Trained GAN Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c16fb-ab6e-4f5d-aafb-e31d529fdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gen_smiles = generate_smiles(n_gen, vocab, num_samples=N_SAMPLES, max_length=MAX_LENGTH, device=DEVICE)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1901be-73d3-4e41-be29-e74411630acb",
   "metadata": {},
   "source": [
    "### Check Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16a141-ffe4-4662-9be6-158b8a078f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "valid_smiles, invalid_smiles = check_smiles_validity(gen_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109fdac-75d0-48a9-a151-b7182938e62f",
   "metadata": {},
   "source": [
    "### Check Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad584e1-2331-44eb-9dca-f22d822fdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "known_can_smiles = process_smiles_in_parallel(smiles_list=smilesList, function_object=canonicalize_smiles, n_processors=N_PROCESSORS)\n",
    "print('\\nLen known canonical smiles: ', len(known_can_smiles))\n",
    "\n",
    "##iterate over unique valid smiles generations, then compare with known smiles\n",
    "print('\\nChecking Novelty of Unique GAN Generated Samples')\n",
    "novel_smiles = [] \n",
    "for smiles in list(set(valid_smiles)):\n",
    "    can_smiles = canonicalize_smiles(smiles)\n",
    "    if is_novel(can_smiles, known_can_smiles):\n",
    "        novel_smiles.append(smiles)\n",
    "\n",
    "print('\\nNovel Cnt: ', len(novel_smiles))\n",
    "print('\\n----------------------Novel Smiles----------------------')\n",
    "for i, smiles in enumerate(novel_smiles):\n",
    "    print(f'\\n{i}. {smiles}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81957a4-d19e-44b4-bef7-3ee6e565e57f",
   "metadata": {},
   "source": [
    "### Check Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f10c88-fb23-47b5-b729-d153c59ef37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "aq_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=estimate_solubility, n_processors=N_PROCESSORS)\n",
    "print('\\nKnown Smiles Solubility Score (logS) Stats')\n",
    "print('Min: ', np.round(np.min(aq_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(aq_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(aq_scores_smilesList), 3))\n",
    "\n",
    "GAN_aq_scores_smilesList = process_smiles_in_parallel(smiles_list=list(set(valid_smiles)), function_object=estimate_solubility, n_processors=N_PROCESSORS)\n",
    "print('\\nGAN Generated Smiles Solubility Score (logS) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_aq_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_aq_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_aq_scores_smilesList), 3))\n",
    "\n",
    "##iterate over unique valid smiles generations, then compare with known smiles\n",
    "print('\\nGAN Generated Smiles Solubility Score (logS)')\n",
    "for smiles in list(set(valid_smiles)):\n",
    "    logS = estimate_solubility(smiles)\n",
    "    print('Solubility Score: ', logS)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0d695-f3a4-4bbb-8658-ff27d56c730b",
   "metadata": {},
   "source": [
    "### Calculate Druglikeliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afac01-7ab5-4cc9-ad49-da739044cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qed_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=calculate_qed, n_processors=N_PROCESSORS)\n",
    "print('\\nKnown Smiles Druglikeliness Score (QED) Stats')\n",
    "print('Min: ', np.round(np.min(qed_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(qed_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(qed_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(qed_scores_smilesList), 3))\n",
    "\n",
    "GAN_qed_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=calculate_qed, n_processors=N_PROCESSORS)\n",
    "print('\\nGAN Generated Smiles Druglikeliness Score (QED) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_qed_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_qed_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_qed_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(GAN_qed_scores_smilesList), 3))\n",
    "\n",
    "print('\\nGAN Generated Smiles Druglikeliness Score (QED)')\n",
    "for i, smiles in enumerate(list(set(valid_smiles))):\n",
    "    qed_score = calculate_qed(smiles)\n",
    "    print(f\"{i}. QED score: {qed_score}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f9afc-9bd0-481f-8e8e-4f8fd6a7348b",
   "metadata": {},
   "source": [
    "### Calculate Synthesizeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cb13d5-8f4e-47fd-914a-85f78b117f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sa_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=estimate_synthesizeability, n_processors=N_PROCESSORS)\n",
    "print('\\nKnown Smiles Synthesizeability Score (SA) Stats')\n",
    "print('Min: ', np.round(np.min(sa_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(sa_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(sa_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(sa_scores_smilesList), 3))\n",
    "\n",
    "GAN_sa_scores_smilesList = process_smiles_in_parallel(smiles_list=list(set(valid_smiles)), function_object=estimate_synthesizeability, n_processors=N_PROCESSORS)\n",
    "print('\\nGAN Generated Synthesizeability Score (SA) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_sa_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_sa_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_sa_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(GAN_sa_scores_smilesList), 3))\n",
    "\n",
    "print('\\nGAN Generated Smiles Synthesizeability Score (SA) Examples')\n",
    "for i, smiles in enumerate(list(set(valid_smiles))):\n",
    "    synth_score = estimate_synthesizeability(smiles)\n",
    "    print(f\"{i}. SA score: {synth_score}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606084f-b141-468b-b468-cb340bd2127a",
   "metadata": {},
   "source": [
    "### Get Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203acfbe-957f-4cf3-938a-dc9cae1f1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\\n==================================================Stats==================================================\")\n",
    "basic_stats = summary_stats(valid_smiles, invalid_smiles)\n",
    "\n",
    "print(\"\\n\\n===============================================Valid SMILES===============================================\")\n",
    "for i, smiles in enumerate(list(set(valid_smiles))[: 10]):\n",
    "    print(f'\\n{i}.  {smiles}')\n",
    "\n",
    "print(\"\\n\\n===============================================Inalid SMILES===============================================\")\n",
    "for i, smiles in enumerate(list(set(invalid_smiles))[: 10]):\n",
    "    print(f'\\n{i}.  {smiles}')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c7b0f-2669-4953-8fd4-88edf75c3c82",
   "metadata": {},
   "source": [
    "### Visualize GAN Generated Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2d817-89c9-4257-b384-546f4587ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "##plot a single example\n",
    "img = plot_single_mol(list(set(valid_smiles))[1])\n",
    "img.save(WRITEPATH + '/GAN_generated_img.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6df82-93ca-4453-8fdc-0288e1841124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_img = plot_smiles_grid(smiles_list=list(set(valid_smiles)))\n",
    "with open(WRITEPATH + \"/grid_gan_generated.png\", \"wb\") as f:\n",
    "    f.write(grid_img.data)\n",
    "\n",
    "grid_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93100b42-2f1a-4357-89b4-2e0fbce6aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean and time\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "tf = time.time()\n",
    "print('Total Runtime: ', np.round(tf - t0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafbc97-f89a-4280-bf9e-3a76549faaf8",
   "metadata": {},
   "source": [
    "### REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa00bf-b6db-4c91-882c-55fad3facf70",
   "metadata": {},
   "source": [
    "Alqahtani, H. E. (2019, Dec 19). Applications of Generative Adversarial Networks (GANS): An Updated Review.\n",
    "\n",
    "Arjovsky, M. E. (2017, Jan 26). Wasserstein GAN.\n",
    "\n",
    "Bidisha, S. (2019). NeVAE: A Deep Generative Model for Molecular Graphs.\n",
    "\n",
    "Goodfellow, E. A. (2014, June 10). Generative Adversarial Networks.\n",
    "\n",
    "Jaun-Ni Wu, E. A. (2024). t-SMILES: A Fragment-based Molecular Representation Framework for De Novo Ligand Design. Hunan, China.\n",
    "\n",
    "National Library of Medicine. (2024, July 22). National Center for Biotechnology Information. Retrieved from PubChem: https://pubchem.ncbi.nlm.nih.gov/\n",
    "\n",
    "Nicola De Cao, T. K. (2018). MolGAN: An Implicit Generative Model for Small Molecular Graphs. Stochholm, Sweden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224a033-c5cf-42a1-9eab-90fccae3d7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
