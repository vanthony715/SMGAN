{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e0c6f7-88d5-4ec6-bad4-ad07d8096f83",
   "metadata": {},
   "source": [
    "## Novel Molecule Generation using Bidirectional-Recurrent Neural Networks with Attention Applied to Simplified Molecular Input Line Entry Sysem (SMILES)\n",
    "\n",
    "## Train\n",
    "\n",
    "author: anthony j. vasquez\n",
    "email: vanthony715@gmail.com / avasque1@jh.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5757c5ec-5fe9-4da6-b825-3c0ae45abcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System:  Linux\n",
      "Machine Type::  x86_64\n",
      "Processor Count:  24 \n",
      "\n",
      "CUDA Version\n",
      "CUDNN Version: 90100\n",
      "Number of CUDA Devices: 2\n",
      "Active CUDA Device: 0\n",
      "Available devices: 2, Name: NVIDIA RTX A4000\n",
      "Current CUDA device: 0\n",
      "\n",
      "\n",
      "Using Device: \n",
      " cuda\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "t0 = time.time()\n",
    "\n",
    "import sys\n",
    "sys.path.append('./data/')\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "##had a hard time with this setting on windows os using spyder and jypyter\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import platform\n",
    "print(\"Operating System: \", platform.system())\n",
    "print(\"Machine Type:: \", platform.machine())\n",
    "\n",
    "import multiprocessing as mp\n",
    "max_processors = mp.cpu_count()\n",
    "print('Processor Count: ', max_processors, '\\n')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import BRICS\n",
    "from rdkit.Chem import Descriptors\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Descriptors import CalcMolDescriptors\n",
    "from rdkit.Chem.rdMolDescriptors import GetHashedMorganFingerprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from net import *\n",
    "from utils import *\n",
    "from custom_dataset import *\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache() #empty cache\n",
    "    print('CUDA Version')\n",
    "    print(f'CUDNN Version: {torch.backends.cudnn.version()}')\n",
    "    print(f'Number of CUDA Devices: {torch.cuda.device_count()}')\n",
    "    print(f'Active CUDA Device: {torch.cuda.current_device()}')\n",
    "    print(f'Available devices: {torch.cuda.device_count()}, Name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'Current CUDA device: {torch.cuda.current_device()}')\n",
    "    print('\\n')\n",
    "\n",
    "##hardware params\n",
    "# DEVICE = torch.device('cpu') #DEBUG\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using Device: \\n', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e871a2-9bc2-4747-92a7-23b6bf9956bd",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ddb5d5-a423-434c-a5e3-dc5160bd1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "##OS\n",
    "LINUX = True\n",
    "MULTI_GPU = True #trains using multiple gpus\n",
    "N_PROCESSORS = max_processors - 2\n",
    "\n",
    "##data\n",
    "HOLDOUT_PERC = 0.90\n",
    "TRAIN_BS = 128 #train batch size\n",
    "PREFETCH_FACTOR = 4 #effectively reduces gpu load time \n",
    "NUM_WORKERS = 8\n",
    "\n",
    "##training\n",
    "N_EPOCHS = 40 #num of training epochs\n",
    "OPTIMIZER = 'rmsprop' ##or adam\n",
    "LRG = 0.004086800025392213 #learning rate generator\n",
    "LRD = 0.013448070902660135 #learning rate discriminator\n",
    "LRS_SZ = 5 #learning rate scheduler step size\n",
    "LRS_GAMMA = 0.99 #learning rate scheduler gamma\n",
    "BETAS = (0.5, 0.999) #momentum moving average\n",
    "DROPOUT_PROB = 0.5 #dropout\n",
    "WEIGHT_DECAY = 1e-5 #L2 Regularization\n",
    "RUN_EXTRA_TIMES = 5 #iterate over validator extra times for every one time that the generator ates\n",
    "EMBEDDING_DIM = 32 #how large of a vector to represent input data\n",
    "HIDDEN_DIM = 128 #learned embeddings\n",
    "N_LAYERS = 2 #num gru layers\n",
    "BIDIRECTIONAL = True #makes gru layer bidirectional\n",
    "N_HEADS = 4 #number of heads for attention, scaled dot-product for head's respective section of sequence\n",
    "CLIP_VALUE = 0.008101987508250374 ##WGAN discriminator clip value for training stabalization\n",
    "\n",
    "##inference\n",
    "N_SAMPLES = 1000\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "##visualization params\n",
    "SIGMA = 2 #loss smoothing for lineplot\n",
    "PRINT_LOSS_EVERY = 2 #how many epochs to output loss\n",
    "\n",
    "##logging\n",
    "RESULTS_PATH = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2587588-c844-4fb7-898d-bfc539c24e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Folder at:  ../results/epoch_40_exper_at_datetime_28-08-2024_14-26-14\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "dt_string = now.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "def make_dir(path: str) -> None:\n",
    "    '''\n",
    "    Create results directory\n",
    "    '''\n",
    "    import shutil\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "    print('Created Folder at: ', path)\n",
    "\n",
    "WRITEPATH = RESULTS_PATH + 'epoch_'+ str(N_EPOCHS) + '_exper_at_datetime_' + dt_string\n",
    "make_dir(WRITEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3e7019-b80f-4509-9110-b89fcdcf89e6",
   "metadata": {},
   "source": [
    "#### Open SMILES Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbb68ac-ff6c-4c9f-9384-ebf253063245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len all smiles:  249456\n",
      "Len train smiles:  24945\n",
      "Len holdout smiles:  224511\n",
      "\n",
      "\n",
      "CPU times: user 227 ms, sys: 18.8 ms, total: 246 ms\n",
      "Wall time: 255 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Import the data\n",
    "data_file = pd.read_csv('../data/Zinc_all_smiles_data.txt', header = None)\n",
    "data_file.columns = ['smiles']\n",
    "smilesList = data_file['smiles'].tolist()\n",
    "\n",
    "##split dset\n",
    "train_smiles, holdout_smiles, _, _ = train_test_split(smilesList, smilesList, test_size=HOLDOUT_PERC, random_state=42)\n",
    "print('Len all smiles: ', len(smilesList))\n",
    "print('Len train smiles: ', len(train_smiles))\n",
    "print('Len holdout smiles: ', len(holdout_smiles))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6532e3e2-4fb4-4700-a264-c5397888934b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 610 ms, sys: 22.4 ms, total: 632 ms\n",
      "Wall time: 632 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Example usage:\n",
    "vocab = build_vocabulary(smilesList)\n",
    "max_length = max(len(tokenize_smiles(smiles)) for smiles in smilesList)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc3d097b-0953-437a-9d79-d61c509e76a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Summary: \n",
      "smilesList Len:  249456\n",
      "vocab len:  254593\n",
      "max_length:  27\n",
      "\n",
      "\n",
      "CPU times: user 251 µs, sys: 0 ns, total: 251 µs\n",
      "Wall time: 250 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##define dataset\n",
    "dataset = SMILESDataset(train_smiles, vocab, max_length)\n",
    "\n",
    "##runs slightly faster using linux, because able to use num_workers > 0\n",
    "if LINUX:\n",
    "    dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True, pin_memory=True, prefetch_factor=PREFETCH_FACTOR, num_workers=NUM_WORKERS)\n",
    "else:\n",
    "    ##windows\n",
    "    dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True, pin_memory=True)\n",
    "\n",
    "print('Data Summary: ')\n",
    "print('smilesList Len: ', len(smilesList))\n",
    "print('vocab len: ', len(vocab))\n",
    "print('max_length: ', max_length)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08569a-29af-4a27-81cc-a1d68884606e",
   "metadata": {},
   "source": [
    "### Instantiate GAN and Discriminator Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1d84ab8-00f1-4a8b-b0f1-99244d5715e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 1.39 s, sys: 386 ms, total: 1.77 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##init networks\n",
    "n_gen = Generator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                  num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL).to(DEVICE)\n",
    "\n",
    "n_disc = Discriminator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                       num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL).to(DEVICE)\n",
    "\n",
    "if MULTI_GPU:\n",
    "    ##for multi-gpu\n",
    "    n_gen = nn.DataParallel(n_gen)\n",
    "    n_disc = nn.DataParallel(n_disc)\n",
    "\n",
    "##set optimization\n",
    "if OPTIMIZER == 'rmsprop':\n",
    "    g_opt = torch.optim.RMSprop(n_gen.parameters(), lr=LRG, weight_decay=WEIGHT_DECAY)\n",
    "    d_opt = torch.optim.RMSprop(n_disc.parameters(), lr=LRD, weight_decay=WEIGHT_DECAY)\n",
    "else: \n",
    "    g_opt = optim.Adam(n_gen.parameters(), lr=LRG, betas=BETAS, weight_decay=WEIGHT_DECAY)\n",
    "    d_opt = optim.Adam(n_disc.parameters(), lr=LRD, betas=BETAS, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "##set schedulers\n",
    "schedule_g = StepLR(g_opt, step_size=LRS_SZ, gamma=LRS_GAMMA)\n",
    "schedule_d = StepLR(d_opt, step_size=LRS_SZ, gamma=LRS_GAMMA)\n",
    "\n",
    "##init criterion\n",
    "crit = nn.BCELoss()\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ad908-5714-49da-8573-9e24c6787a12",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e02dd763-5710-49d0-838f-f0b2da6afaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total generator param cnt:  8962624\n",
      "Trainable generator param cnt:  8962624\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal generator param cnt: ', count_parameters(n_gen))\n",
    "print('Trainable generator param cnt: ', count_trainable_parameters(n_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc3af1e-44ae-4bf8-99df-11ecc4491b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Generator(\n",
       "    (embedding): Embedding(254594, 32)\n",
       "    (gru): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede9e83-6d7a-4bae-9e83-c7fa994ea081",
   "metadata": {},
   "source": [
    "### Descriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4bfd49-acc5-40a6-8336-3f52f261f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total discriminator param cnt:  8666945\n",
      "Trainable discriminator param cnt:  8666945\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal discriminator param cnt: ', count_parameters(n_disc))\n",
    "print('Trainable discriminator param cnt: ', count_trainable_parameters(n_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4d5263-2d8c-4459-aa38-056500080368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Discriminator(\n",
       "    (embedding): Embedding(254594, 32)\n",
       "    (gru): GRU(32, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "    (fc_reduce): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_disc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e36c28-ff8b-433a-9217-ddb8844f3555",
   "metadata": {},
   "source": [
    "### Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3e547-77f1-4756-9d42-10783e86cec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:38<00:00,  5.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/40], D Loss: 1.37957, G Loss: 0.77806, Runtime/Epoch: 38.30338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:34<00:00,  5.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/40], D Loss: 1.37172, G Loss: 0.68044, Runtime/Epoch: 34.99476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/40], D Loss: 1.37798, G Loss: 0.69973, Runtime/Epoch: 35.22251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:34<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/40], D Loss: 1.37495, G Loss: 0.67075, Runtime/Epoch: 34.94411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/40], D Loss: 1.37500, G Loss: 0.71573, Runtime/Epoch: 35.42757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/40], D Loss: 1.38095, G Loss: 0.63087, Runtime/Epoch: 35.27564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:34<00:00,  5.58it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:34<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/40], D Loss: 1.35046, G Loss: 0.74246, Runtime/Epoch: 34.88770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/40], D Loss: 1.38231, G Loss: 0.64264, Runtime/Epoch: 35.35700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/40], D Loss: 1.36482, G Loss: 0.64516, Runtime/Epoch: 35.44228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/40], D Loss: 1.37341, G Loss: 0.66692, Runtime/Epoch: 35.36709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/40], D Loss: 1.37948, G Loss: 0.78675, Runtime/Epoch: 35.48969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 195/195 [00:35<00:00,  5.57it/s]\n",
      "  7%|█████▍                                                                            | 13/195 [00:02<00:32,  5.59it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hist, gnet, dnet =  train_gan(generator=n_gen, discriminator=n_disc, g_optimizer=g_opt, d_optimizer=d_opt, criterion=crit, \n",
    "                              g_schedule=schedule_g, d_schedule=schedule_d, data_loader=dataloader, run_extra_times=RUN_EXTRA_TIMES, \n",
    "                              clip_value=CLIP_VALUE, n_epochs=N_EPOCHS, multi_gpu=MULTI_GPU, device=DEVICE, print_loss_every=PRINT_LOSS_EVERY)\n",
    "\n",
    "##save both networks\n",
    "torch.save(gnet.state_dict(), WRITEPATH + '/gnet.pt')\n",
    "torch.save(dnet.state_dict(), WRITEPATH + '/dnet.pt')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8853dc92-f28d-4c5c-ae09-9be6616b069e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "plot_losses(history=hist, sigma=SIGMA, save=True, savepath=WRITEPATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd636bc-0ec3-432e-b6b1-c5a6598cd833",
   "metadata": {},
   "source": [
    "### Generate Molecules Using Trained GAN Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781c16fb-ab6e-4f5d-aafb-e31d529fdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gen_smiles = generate_smiles(n_gen, vocab, num_samples=N_SAMPLES, max_length=MAX_LENGTH, device=DEVICE)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1901be-73d3-4e41-be29-e74411630acb",
   "metadata": {},
   "source": [
    "### Check Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e16a141-ffe4-4662-9be6-158b8a078f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "valid_smiles, invalid_smiles = check_smiles_validity(gen_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c109fdac-75d0-48a9-a151-b7182938e62f",
   "metadata": {},
   "source": [
    "### Check Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad584e1-2331-44eb-9dca-f22d822fdb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "known_can_smiles = process_smiles_in_parallel(smiles_list=smilesList, function_object=canonicalize_smiles, n_processors=N_PROCESSORS)\n",
    "print('\\nLen known canonical smiles: ', len(known_can_smiles))\n",
    "\n",
    "##iterate over unique valid smiles generations, then compare with known smiles\n",
    "print('\\nChecking Novelty of Unique GAN Generated Samples')\n",
    "novel_smiles = [] \n",
    "for smiles in list(set(valid_smiles)):\n",
    "    can_smiles = canonicalize_smiles(smiles)\n",
    "    if is_novel(can_smiles, known_can_smiles):\n",
    "        novel_smiles.append(smiles)\n",
    "\n",
    "print('\\nNovel Cnt: ', len(novel_smiles))\n",
    "print('\\n----------------------Novel Smiles----------------------')\n",
    "for i, smiles in enumerate(novel_smiles):\n",
    "    print(f'\\n{i}. {smiles}')\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81957a4-d19e-44b4-bef7-3ee6e565e57f",
   "metadata": {},
   "source": [
    "### Check Solubility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f10c88-fb23-47b5-b729-d153c59ef37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "aq_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=estimate_solubility, n_processors=N_PROCESSORS)\n",
    "aq_scores_smilesList = MinMaxScaler().fit_transform(np.array(aq_scores_smilesList).reshape(-1, 1))\n",
    "print('\\nKnown Smiles Solubility Score (logS) Stats')\n",
    "print('Min: ', np.round(np.min(aq_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(aq_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(aq_scores_smilesList), 3))\n",
    "\n",
    "GAN_aq_scores_smilesList = process_smiles_in_parallel(smiles_list=list(set(valid_smiles)), function_object=estimate_solubility, n_processors=N_PROCESSORS)\n",
    "scaler = MinMaxScaler()\n",
    "GAN_aq_scores_smilesList = scaler.fit_transform(np.array(GAN_aq_scores_smilesList).reshape(-1, 1))\n",
    "print('\\nGAN Generated Smiles Solubility Score (logS) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_aq_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_aq_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_aq_scores_smilesList), 3))\n",
    "\n",
    "##iterate over unique valid smiles generations, then compare with known smiles\n",
    "print('\\nGAN Generated Smiles Solubility Score (logS)')\n",
    "logS_list = [estimate_solubility(i) for i in list(set(valid_smiles))]\n",
    "logS = scaler.transform(np.array(logS_list).reshape(-1, 1))\n",
    "\n",
    "for sol_score in logS:\n",
    "    print('Solubility Score: ', np.round(sol_score.item(), 3))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9b3776-db11-4220-8245-4753e32a0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "logS[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c0d695-f3a4-4bbb-8658-ff27d56c730b",
   "metadata": {},
   "source": [
    "### Calculate Druglikeliness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0afac01-7ab5-4cc9-ad49-da739044cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "qed_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, function_object=calculate_qed, n_processors=N_PROCESSORS)\n",
    "print('\\nKnown Smiles Druglikeliness Score (QED) Stats')\n",
    "print('Min: ', np.round(np.min(qed_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(qed_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(qed_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(qed_scores_smilesList), 3))\n",
    "\n",
    "GAN_qed_scores_smilesList = process_smiles_in_parallel(smiles_list=list(set(valid_smiles)), function_object=calculate_qed, n_processors=N_PROCESSORS)\n",
    "print('\\nGAN Generated Smiles Druglikeliness Score (QED) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_qed_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_qed_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_qed_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(GAN_qed_scores_smilesList), 3))\n",
    "\n",
    "print('\\nGAN Generated Smiles Druglikeliness Score (QED)')\n",
    "for i, smiles in enumerate(list(set(valid_smiles))):\n",
    "    qed_score = calculate_qed(smiles)\n",
    "    print(f\"{i}. QED score: {qed_score}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f9afc-9bd0-481f-8e8e-4f8fd6a7348b",
   "metadata": {},
   "source": [
    "### Calculate Synthesizeability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d9a38-e256-4d59-a3a7-7b0541da91d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "##gen scores for all smiles\n",
    "sa_scores_smilesList = process_smiles_in_parallel(smiles_list=smilesList, \n",
    "                                                 function_object=calculate_sa_score, \n",
    "                                                 n_processors=N_PROCESSORS)\n",
    "\n",
    "##gen scores for GAN generated samples\n",
    "GAN_sa_scores_smilesList = process_smiles_in_parallel(smiles_list=list(set(valid_smiles)), \n",
    "                                                      function_object=calculate_sa_score, \n",
    "                                                      n_processors=N_PROCESSORS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d230c7-88de-46d0-b6b9-5485e00e91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nKnown Smiles Synthesizeability Score (SA) Stats')\n",
    "print('Min: ', np.round(np.min(sa_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(sa_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(sa_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(sa_scores_smilesList), 3))\n",
    "\n",
    "print('\\nGAN Generated Smiles Synthesizeability Score (SA) Stats')\n",
    "print('Min: ', np.round(np.min(GAN_sa_scores_smilesList), 3))\n",
    "print('Max: ', np.round(np.max(GAN_sa_scores_smilesList), 3))\n",
    "print('Mean: ', np.round(np.mean(GAN_sa_scores_smilesList), 3))\n",
    "print('Std: ', np.round(np.std(GAN_sa_scores_smilesList), 3))\n",
    "\n",
    "print('\\nUnique Valid GAN Generated Sample SA Scores')\n",
    "for i, sa_score in enumerate(GAN_sa_scores_smilesList):\n",
    "    print(f\"{i}. SA score: {sa_score}\")\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606084f-b141-468b-b468-cb340bd2127a",
   "metadata": {},
   "source": [
    "### Get Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203acfbe-957f-4cf3-938a-dc9cae1f1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "print(\"\\n\\n==================================================Stats==================================================\")\n",
    "basic_stats = summary_stats(valid_smiles, invalid_smiles)\n",
    "\n",
    "print(\"\\n\\n===============================================Valid SMILES===============================================\")\n",
    "for i, smiles in enumerate(list(set(valid_smiles))[: 10]):\n",
    "    print(f'\\n{i}.  {smiles}')\n",
    "\n",
    "print(\"\\n\\n===============================================Inalid SMILES===============================================\")\n",
    "for i, smiles in enumerate(list(set(invalid_smiles))[: 10]):\n",
    "    print(f'\\n{i}.  {smiles}')\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065c7b0f-2669-4953-8fd4-88edf75c3c82",
   "metadata": {},
   "source": [
    "### Visualize GAN Generated Molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff2d817-89c9-4257-b384-546f4587ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "##plot a single example\n",
    "img = plot_single_mol(list(set(valid_smiles))[1])\n",
    "img.save(WRITEPATH + '/GAN_generated_img.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d6df82-93ca-4453-8fdc-0288e1841124",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_img = plot_smiles_grid(smiles_list=list(set(valid_smiles)))\n",
    "with open(WRITEPATH + \"/grid_gan_generated.png\", \"wb\") as f:\n",
    "    f.write(grid_img.data)\n",
    "\n",
    "grid_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93100b42-2f1a-4357-89b4-2e0fbce6aa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "##clean and time\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "tf = time.time()\n",
    "print('Total Runtime: ', np.round(tf - t0, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaafbc97-f89a-4280-bf9e-3a76549faaf8",
   "metadata": {},
   "source": [
    "### REFERENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f224a033-c5cf-42a1-9eab-90fccae3d7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
