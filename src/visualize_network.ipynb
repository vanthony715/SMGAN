{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e0c6f7-88d5-4ec6-bad4-ad07d8096f83",
   "metadata": {},
   "source": [
    "## Novel Molecule Generation using Bidirectional-Recurrent Neural Networks with Attention Applied to Simplified Molecular Input Line Entry Sysem (SMILES)\n",
    "\n",
    "## Train\n",
    "\n",
    "author: anthony j. vasquez\n",
    "email: vanthony715@gmail.com / avasque1@jh.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5757c5ec-5fe9-4da6-b825-3c0ae45abcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operating System:  Linux\n",
      "Machine Type::  x86_64\n",
      "Processor Count:  24 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "t0 = time.time()\n",
    "\n",
    "import sys\n",
    "sys.path.append('./data/')\n",
    "\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "import os\n",
    "##had a hard time with this setting on windows os using spyder and jypyter\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import platform\n",
    "print(\"Operating System: \", platform.system())\n",
    "print(\"Machine Type:: \", platform.machine())\n",
    "\n",
    "import multiprocessing as mp\n",
    "max_processors = mp.cpu_count()\n",
    "print('Processor Count: ', max_processors, '\\n')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# !pip install torchviz\n",
    "# !pip install torchinfo\n",
    "from torchinfo import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "from net import *\n",
    "from utils import *\n",
    "from custom_dataset import *\n",
    "\n",
    "##hardware params\n",
    "DEVICE = torch.device('cpu') #DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e871a2-9bc2-4747-92a7-23b6bf9956bd",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33ddb5d5-a423-434c-a5e3-dc5160bd1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "##data\n",
    "HOLDOUT_PERC = 0.90\n",
    "TRAIN_BS = 128 #train batch size\n",
    "PREFETCH_FACTOR = 4 #effectively reduces gpu load time \n",
    "NUM_WORKERS = 8\n",
    "\n",
    "##training\n",
    "N_EPOCHS = 500 #num of training epochs\n",
    "OPTIMIZER = 'rmsprop' ##or adam\n",
    "LRG = 0.004086800025392213 #learning rate generator\n",
    "LRD = 0.013448070902660135 #learning rate discriminator\n",
    "LRS_SZ = 5 #learning rate scheduler step size\n",
    "LRS_GAMMA = 0.99 #learning rate scheduler gamma\n",
    "BETAS = (0.5, 0.999) #momentum moving average\n",
    "DROPOUT_PROB = 0.5 #dropout\n",
    "WEIGHT_DECAY = 1e-5 #L2 Regularization\n",
    "RUN_EXTRA_TIMES = 3 #iterate over validator extra times for every one time that the generator ates\n",
    "EMBEDDING_DIM = 32 #how large of a vector to represent input data\n",
    "HIDDEN_DIM = 128 #learned embeddings\n",
    "N_LAYERS = 2 #num gru layers\n",
    "BIDIRECTIONAL = True #makes gru layer bidirectional\n",
    "N_HEADS = 4 #number of heads for attention, scaled dot-product for head's respective section of sequence\n",
    "CLIP_VALUE = 0.008101987508250374 ##WGAN discriminator clip value for training stabalization\n",
    "\n",
    "##inference\n",
    "N_SAMPLES = 1000\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "##visualization params\n",
    "SIGMA = 2 #loss smoothing for lineplot\n",
    "PRINT_LOSS_EVERY = 2 #how many epochs to output loss\n",
    "\n",
    "##logging\n",
    "RESULTS_PATH = '../results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "179e6abc-bf3a-4a8e-bf25-be7c10d97c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len all smiles:  249456\n",
      "Len train smiles:  24945\n",
      "Len holdout smiles:  224511\n",
      "\n",
      "\n",
      "CPU times: user 269 ms, sys: 18.6 ms, total: 287 ms\n",
      "Wall time: 287 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### Import the data\n",
    "data_file = pd.read_csv('../data/Zinc_all_smiles_data.txt', header = None)\n",
    "data_file.columns = ['smiles']\n",
    "smilesList = data_file['smiles'].tolist()\n",
    "\n",
    "##split dset\n",
    "train_smiles, holdout_smiles, _, _ = train_test_split(smilesList, smilesList, test_size=HOLDOUT_PERC, random_state=42)\n",
    "print('Len all smiles: ', len(smilesList))\n",
    "print('Len train smiles: ', len(train_smiles))\n",
    "print('Len holdout smiles: ', len(holdout_smiles))\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95d6bb05-853b-4a07-830c-78a42a0a6d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 686 ms, sys: 10.2 ms, total: 696 ms\n",
      "Wall time: 695 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Example usage:\n",
    "vocab = build_vocabulary(smilesList)\n",
    "max_length = max(len(tokenize_smiles(smiles)) for smiles in smilesList)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cd0d4c-0592-47d7-ad62-d8d527fb7a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Summary: \n",
      "smilesList Len:  249456\n",
      "vocab len:  254593\n",
      "max_length:  27\n",
      "\n",
      "\n",
      "CPU times: user 239 µs, sys: 24 µs, total: 263 µs\n",
      "Wall time: 260 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##define dataset\n",
    "dataset = SMILESDataset(train_smiles, vocab, max_length)\n",
    "dataloader = DataLoader(dataset, batch_size=TRAIN_BS, shuffle=True, pin_memory=False)\n",
    "\n",
    "print('Data Summary: ')\n",
    "print('smilesList Len: ', len(smilesList))\n",
    "print('vocab len: ', len(vocab))\n",
    "print('max_length: ', max_length)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea08569a-29af-4a27-81cc-a1d68884606e",
   "metadata": {},
   "source": [
    "### Instantiate GAN and Discriminator Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d84ab8-00f1-4a8b-b0f1-99244d5715e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 83.2 ms, sys: 11 ms, total: 94.2 ms\n",
      "Wall time: 93.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "##init networks\n",
    "n_gen = Generator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                  num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "n_disc = Discriminator(vocab_size=len(vocab) + 1, embedding_dim=EMBEDDING_DIM, hidden_dim=HIDDEN_DIM, num_layers=N_LAYERS, max_length=max_length, \n",
    "                       num_heads=N_HEADS, dropout_prob=DROPOUT_PROB, bidirectional=BIDIRECTIONAL)\n",
    "\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8ad908-5714-49da-8573-9e24c6787a12",
   "metadata": {},
   "source": [
    "### Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02dd763-5710-49d0-838f-f0b2da6afaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total generator param cnt:  8962624\n",
      "Trainable generator param cnt:  8962624\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal generator param cnt: ', count_parameters(n_gen))\n",
    "print('Trainable generator param cnt: ', count_trainable_parameters(n_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcc3af1e-44ae-4bf8-99df-11ecc4491b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/195 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Size:  torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Generator                                [128, 27]                 --\n",
      "├─Embedding: 1-1                         [128, 27, 32]             8,147,008\n",
      "├─GRU: 1-2                               [128, 27, 256]            420,864\n",
      "├─Dropout: 1-3                           [128, 27, 256]            --\n",
      "├─MultiheadAttention: 1-4                [27, 128, 256]            263,168\n",
      "├─Linear: 1-5                            [128, 27, 512]            131,584\n",
      "==========================================================================================\n",
      "Total params: 8,962,624\n",
      "Trainable params: 8,962,624\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.51\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 22.12\n",
      "Params size (MB): 34.80\n",
      "Estimated Total Size (MB): 56.93\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# show_model_details(model=n_gen)\n",
    "\n",
    "##just get the size of the input\n",
    "for real_smiles in tqdm(dataloader):\n",
    "    input_size = real_smiles.shape\n",
    "    example_input = real_smiles.to(DEVICE)\n",
    "    print('Input Size: ', input_size)\n",
    "    break\n",
    "    \n",
    "print(summary(n_gen, input_size=input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2048bf60-7a75-46e2-b4f8-89d34c2e6d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ##TODO get the graph to work. There is an everything on same device error.\n",
    "# example_input = torch.randint(0, 10000, (32, 100)).long().to(DEVICE)\n",
    "\n",
    "# # Forward pass through the model\n",
    "# output = n_gen(example_input)\n",
    "    \n",
    "# Generate the graph\n",
    "# graph = make_dot(output, params=dict(n_gen.named_parameters()))\n",
    "# graph = make_dot(output, params=dict(n_gen.named_parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cede9e83-6d7a-4bae-9e83-c7fa994ea081",
   "metadata": {},
   "source": [
    "### Descriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d4bfd49-acc5-40a6-8336-3f52f261f12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total discriminator param cnt:  8666945\n",
      "Trainable discriminator param cnt:  8666945\n"
     ]
    }
   ],
   "source": [
    "print('\\nTotal discriminator param cnt: ', count_parameters(n_disc))\n",
    "print('Trainable discriminator param cnt: ', count_trainable_parameters(n_disc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4d5263-2d8c-4459-aa38-056500080368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Discriminator                            [128, 1]                  --\n",
      "├─Embedding: 1-1                         [128, 27, 32]             8,147,008\n",
      "├─GRU: 1-2                               [128, 27, 256]            420,864\n",
      "├─Linear: 1-3                            [128, 27, 128]            32,896\n",
      "├─Dropout: 1-4                           [128, 27, 128]            --\n",
      "├─MultiheadAttention: 1-5                [27, 128, 128]            66,048\n",
      "├─Linear: 1-6                            [128, 1]                  129\n",
      "==========================================================================================\n",
      "Total params: 8,666,945\n",
      "Trainable params: 8,666,945\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.50\n",
      "==========================================================================================\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.50\n",
      "Params size (MB): 34.40\n",
      "Estimated Total Size (MB): 45.92\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# show_model_details(model=n_disc)\n",
    "print(summary(n_disc, input_size=input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93100b42-2f1a-4357-89b4-2e0fbce6aa77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Runtime:  7.999\n"
     ]
    }
   ],
   "source": [
    "##clean and time\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "tf = time.time()\n",
    "print('Total Runtime: ', np.round(tf - t0, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
